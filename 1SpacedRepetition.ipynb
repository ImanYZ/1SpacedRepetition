{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import absolute_import, division, print_function, unicode_literals\n",
    "\n",
    "import collections\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "from tensorflow import feature_column\n",
    "from tensorflow.keras import layers\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "dataframe = pd.read_csv(\"Practice_Log_Demographics.csv\")\n",
    "dataframe = dataframe[(dataframe[\"term\"] == \"WN 2018\") |\n",
    "                      (dataframe[\"term\"] == \"FA 2018\") |\n",
    "                      (dataframe[\"term\"] == \"WN 2019\") |\n",
    "                      (dataframe[\"term\"] == \"FA 2019\")]\n",
    "dataframe['target'] = np.where(dataframe['q']>=4, 1, 0)\n",
    "dataframe = dataframe.drop(['q'], axis=1)\n",
    "dataframe['available_flashcards'] = dataframe[\"day's_available_flashcards\"][:]\n",
    "dataframe = dataframe.drop([\"day's_available_flashcards\"], axis=1)\n",
    "dataframe = dataframe.drop([\"Unnamed: 0\"], axis=1)\n",
    "dataframe = dataframe.drop([\"Final_Exam\"], axis=1)\n",
    "dataframe = dataframe.drop([\"Final_Exam_Std\"], axis=1)\n",
    "dataframe = dataframe.drop([\"Final_Exam_Percent\"], axis=1)\n",
    "dataframe = dataframe.drop([\"Final_Exam_0_1\"], axis=1)\n",
    "dataframe = dataframe.drop([\"Final_Exam_log_trans\"], axis=1)\n",
    "dataframe = dataframe.drop([\"final_course_grade\"], axis=1)\n",
    "dataframe = dataframe.drop([\"Course_Grade\"], axis=1)\n",
    "dataframe = dataframe.drop([\"Course_Grade_0_1\"], axis=1)\n",
    "dataframe = dataframe.drop([\"Course_Grade_log_trans\"], axis=1)\n",
    "dataframe = dataframe.drop([\"Practice\"], axis=1)\n",
    "dataframe = dataframe.drop([\"practice_score\"], axis=1)\n",
    "dataframe = dataframe.drop([\"parentsGrossIncome\"], axis=1)\n",
    "dataframe = dataframe.drop([\"parentsGrossIncomeBinary\"], axis=1)\n",
    "dataframe = dataframe.drop([\"parentsMaxEducation\"], axis=1)\n",
    "dataframe = dataframe.drop([\"parentsMaxEducationBinary\"], axis=1)\n",
    "dataframe = dataframe.drop([\"permanentCountry\"], axis=1)\n",
    "dataframe = dataframe.drop([\"HSCalculusTaken\"], axis=1)\n",
    "dataframe = dataframe.drop([\"maxACTComp\"], axis=1)\n",
    "dataframe = dataframe.drop([\"maxACTEngl\"], axis=1)\n",
    "dataframe = dataframe.drop([\"maxACTMath\"], axis=1)\n",
    "dataframe = dataframe.drop([\"maxACTSciReason\"], axis=1)\n",
    "dataframe = dataframe.drop([\"MAX_AP_CALAB_TEST_SCR\"], axis=1)\n",
    "dataframe = dataframe.drop([\"MAX_AP_CALBC_TEST_SCR\"], axis=1)\n",
    "dataframe = dataframe.drop([\"MAX_AP_CSAB_TEST_SCR\"], axis=1)\n",
    "dataframe = dataframe.drop([\"MAX_AP_CSPRC_TEST_SCR\"], axis=1)\n",
    "dataframe = dataframe.drop([\"MAX_SATI_ASC_X_PCTL\"], axis=1)\n",
    "dataframe = dataframe.drop([\"MAX_SATI_ERWS_PCTL\"], axis=1)\n",
    "dataframe = dataframe.drop([\"MAX_SATI_MATH_PCTL\"], axis=1)\n",
    "dataframe = dataframe.drop([\"MAX_SATI_TOTAL_CALC_SCR\"], axis=1)\n",
    "dataframe = dataframe.drop([\"MAX_TOEFL_TOTAL_SCR\"], axis=1)\n",
    "dataframe = dataframe.drop([\"citizenship\"], axis=1)\n",
    "dataframe = dataframe.drop([\"USCitizenship\"], axis=1)\n",
    "dataframe = dataframe.drop([\"nativeEnglish\"], axis=1)\n",
    "dataframe = dataframe.drop([\"minority\"], axis=1)\n",
    "dataframe = dataframe.drop([\"ethnicity\"], axis=1)\n",
    "dataframe = dataframe.drop([\"gender\"], axis=1)\n",
    "dataframe = dataframe.drop([\"international\"], axis=1)\n",
    "dataframe = dataframe.drop([\"academicLevel\"], axis=1)\n",
    "dataframe = dataframe.drop([\"athlete\"], axis=1)\n",
    "dataframe = dataframe.drop([\"honorsPro\"], axis=1)\n",
    "dataframe = dataframe.drop([\"cumGPA\"], axis=1)\n",
    "dataframe = dataframe.drop([\"highSchoolState\"], axis=1)\n",
    "dataframe = dataframe.drop([\"program1\"], axis=1)\n",
    "dataframe = dataframe.drop([\"program1Major1\"], axis=1)\n",
    "dataframe = dataframe.drop([\"program1Major2\"], axis=1)\n",
    "dataframe = dataframe.drop([\"program1Minor1\"], axis=1)\n",
    "dataframe = dataframe.drop([\"program1Minor2\"], axis=1)\n",
    "dataframe = dataframe.drop([\"program2\"], axis=1)\n",
    "dataframe = dataframe.drop([\"program2Major1\"], axis=1)\n",
    "dataframe = dataframe.drop([\"program2Major2\"], axis=1)\n",
    "dataframe = dataframe.drop([\"program2Minor1\"], axis=1)\n",
    "dataframe = dataframe.drop([\"program2Minor2\"], axis=1)\n",
    "dataframe = dataframe.drop([\"career\"], axis=1)\n",
    "dataframe = dataframe.drop([\"CATLG_NBR\"], axis=1)\n",
    "dataframe = dataframe.drop([\"SBJCT_CD\"], axis=1)\n",
    "dataframe = dataframe.drop([\"TERM_SHORT_DES.1\"], axis=1)\n",
    "dataframe = dataframe.drop([\"classGraded\"], axis=1)\n",
    "dataframe = dataframe.drop([\"classHonors\"], axis=1)\n",
    "dataframe = dataframe.drop([\"classEnd\"], axis=1)\n",
    "dataframe = dataframe.drop([\"classStart\"], axis=1)\n",
    "dataframe = dataframe.drop([\"classSectionCode\"], axis=1)\n",
    "dataframe = dataframe.drop([\"courseStudentsNum\"], axis=1)\n",
    "dataframe = dataframe.drop([\"classType\"], axis=1)\n",
    "dataframe = dataframe.drop([\"courseGPA\"], axis=1)\n",
    "dataframe = dataframe.drop([\"grade\"], axis=1)\n",
    "dataframe = dataframe.drop([\"includedInGPA\"], axis=1)\n",
    "dataframe = dataframe.drop([\"semester\"], axis=1)\n",
    "dataframe = dataframe.drop([\"instructor\"], axis=1)\n",
    "dataframe = dataframe.drop([\"practice_tool\"], axis=1)\n",
    "dataframe = dataframe.drop([\"treatment\"], axis=1)\n",
    "dataframe = dataframe.drop([\"gradingType\"], axis=1)\n",
    "dataframe = dataframe.drop([\"prior_gpa\"], axis=1)\n",
    "dataframe = dataframe.drop([\"program_Cat\"], axis=1)\n",
    "dataframe = dataframe.drop([\"cumGPA_0_1\"], axis=1)\n",
    "dataframe = dataframe.drop([\"user_id.x\"], axis=1)\n",
    "dataframe = dataframe.drop([\"practice_count\"], axis=1)\n",
    "dataframe = dataframe.drop([\"practice_days\"], axis=1)\n",
    "dataframe = dataframe.drop([\"course_name.y\"], axis=1)\n",
    "dataframe = dataframe.drop([\"timezoneoffset\"], axis=1)\n",
    "dataframe = dataframe.drop([\"next_eligible_date\"], axis=1)\n",
    "dataframe = dataframe.drop([\"start_practice\"], axis=1)\n",
    "dataframe = dataframe.drop([\"end_practice\"], axis=1)\n",
    "dataframe = dataframe.drop([\"Repeated\"], axis=1)\n",
    "dataframe = dataframe.drop([\"minorsCount\"], axis=1)\n",
    "dataframe = dataframe.drop([\"WhiteOrAsian\"], axis=1)\n",
    "dataframe = dataframe.drop([\"section\"], axis=1)\n",
    "dataframe = dataframe.drop([\"trials_num\"], axis=1)\n",
    "dataframe = dataframe.drop([\"e_factor\"], axis=1)\n",
    "dataframe = dataframe.drop([\"i_interval\"], axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "term                     object\n",
       "firstTerm                object\n",
       "highSchoolGPA           float64\n",
       "PubMathScore            float64\n",
       "parentsDependentsNum    float64\n",
       "singleParent              int64\n",
       "birthMonth                int64\n",
       "birthYear                 int64\n",
       "majorsCount               int64\n",
       "academicLoad             object\n",
       "careerLevel              object\n",
       "residency                object\n",
       "residentialCollege        int64\n",
       "termCreditsGPA          float64\n",
       "termCreditsNoGPA        float64\n",
       "classStudentsNum          int64\n",
       "classGPA                float64\n",
       "exclClassCumGPA         float64\n",
       "semesterWinter            int64\n",
       "instructor_1              int64\n",
       "Pass_Fail                 int64\n",
       "Female                    int64\n",
       "NonNativeEnglish          int64\n",
       "White                     int64\n",
       "Asian                     int64\n",
       "Hispanic                  int64\n",
       "AfricanAmerican           int64\n",
       "OtherEthnicities          int64\n",
       "parentsGraduateEdu        int64\n",
       "parentsHighIncome       float64\n",
       "highSchoolMI            float64\n",
       "minorityGroup             int64\n",
       "international_1           int64\n",
       "Junior                    int64\n",
       "Sophomore                 int64\n",
       "Senior                    int64\n",
       "Minors_1                  int64\n",
       "Minors_2OrMore            int64\n",
       "athlete_1                 int64\n",
       "honorsPro_1               int64\n",
       "programBusiness           int64\n",
       "programEngineering        int64\n",
       "programInformation        int64\n",
       "programOther              int64\n",
       "user_id.y                 int64\n",
       "chapter_label            object\n",
       "sub_chapter_label        object\n",
       "question_name            object\n",
       "days_offset               int64\n",
       "target                    int32\n",
       "available_flashcards      int64\n",
       "dtype: object"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# dataframe.shape\n",
    "dataframe.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['FA 2019',\n",
       " 'FA 2019',\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " 0,\n",
       " 4,\n",
       " 1999,\n",
       " 1,\n",
       " 0,\n",
       " 'Full-Time',\n",
       " 'Undergraduate',\n",
       " 'In State',\n",
       " 0,\n",
       " 11.0,\n",
       " 1.0,\n",
       " 159,\n",
       " 3.326,\n",
       " 4.0,\n",
       " ' ',\n",
       " 'SI 106 001 - UC 109 001',\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " nan,\n",
       " nan,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 139,\n",
       " 'Functions',\n",
       " 'Functionscancallotherfunctions',\n",
       " 'ac11_9_1',\n",
       " 1,\n",
       " 1.3,\n",
       " 1,\n",
       " 75,\n",
       " 0,\n",
       " 26]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataframe[dataframe.isnull().any(axis=1)].iloc[0].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 365882 entries, 0 to 365881\n",
      "Data columns (total 58 columns):\n",
      "term                    365882 non-null object\n",
      "firstTerm               365882 non-null object\n",
      "highSchoolGPA           317300 non-null float64\n",
      "PubMathScore            352371 non-null float64\n",
      "parentsDependentsNum    357213 non-null float64\n",
      "singleParent            365882 non-null int64\n",
      "birthMonth              365882 non-null int64\n",
      "birthYear               365882 non-null int64\n",
      "majorsCount             365882 non-null int64\n",
      "minorsCount             365882 non-null object\n",
      "academicLoad            365882 non-null object\n",
      "careerLevel             365882 non-null object\n",
      "residency               365882 non-null object\n",
      "residentialCollege      365882 non-null int64\n",
      "termCreditsGPA          365882 non-null float64\n",
      "termCreditsNoGPA        365882 non-null float64\n",
      "classStudentsNum        365882 non-null int64\n",
      "classGPA                365882 non-null float64\n",
      "exclClassCumGPA         365882 non-null float64\n",
      "Repeated                365882 non-null object\n",
      "section                 365882 non-null object\n",
      "semesterWinter          365882 non-null int64\n",
      "instructor_1            365882 non-null int64\n",
      "Pass_Fail               365882 non-null int64\n",
      "Female                  365882 non-null int64\n",
      "NonNativeEnglish        365882 non-null int64\n",
      "White                   365882 non-null int64\n",
      "Asian                   365882 non-null int64\n",
      "WhiteOrAsian            365882 non-null int64\n",
      "Hispanic                365882 non-null int64\n",
      "AfricanAmerican         365882 non-null int64\n",
      "OtherEthnicities        365882 non-null int64\n",
      "parentsGraduateEdu      365882 non-null int64\n",
      "parentsHighIncome       250815 non-null float64\n",
      "highSchoolMI            348016 non-null float64\n",
      "minorityGroup           365882 non-null int64\n",
      "international_1         365882 non-null int64\n",
      "Junior                  365882 non-null int64\n",
      "Sophomore               365882 non-null int64\n",
      "Senior                  365882 non-null int64\n",
      "Minors_1                365882 non-null int64\n",
      "Minors_2OrMore          365882 non-null int64\n",
      "athlete_1               365882 non-null int64\n",
      "honorsPro_1             365882 non-null int64\n",
      "programBusiness         365882 non-null int64\n",
      "programEngineering      365882 non-null int64\n",
      "programInformation      365882 non-null int64\n",
      "programOther            365882 non-null int64\n",
      "user_id.y               365882 non-null int64\n",
      "chapter_label           365882 non-null object\n",
      "sub_chapter_label       365882 non-null object\n",
      "question_name           365882 non-null object\n",
      "i_interval              365882 non-null int64\n",
      "e_factor                365882 non-null float64\n",
      "trials_num              365882 non-null int64\n",
      "days_offset             365882 non-null int64\n",
      "target                  365882 non-null int32\n",
      "available_flashcards    365882 non-null int64\n",
      "dtypes: float64(10), int32(1), int64(36), object(11)\n",
      "memory usage: 163.3+ MB\n"
     ]
    }
   ],
   "source": [
    "dataframe.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'user_id.y'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\core\\indexes\\base.py\u001b[0m in \u001b[0;36mget_loc\u001b[1;34m(self, key, method, tolerance)\u001b[0m\n\u001b[0;32m   3077\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3078\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3079\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'user_id.y'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-80-25289a02ac70>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     59\u001b[0m \u001b[0mdataframe\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'residency'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdataframe\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'residency'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'category'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     60\u001b[0m \u001b[1;31m# dataframe['section'] = dataframe['section'].astype('category')\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 61\u001b[1;33m \u001b[0mdataframe\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'user_id'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdataframe\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'user_id.y'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfloat\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     62\u001b[0m \u001b[0mdataframe\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdataframe\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"user_id.y\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     63\u001b[0m \u001b[0mdataframe\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'user_id'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdataframe\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'user_id'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mint\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   2686\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_getitem_multilevel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2687\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2688\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_getitem_column\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2689\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2690\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_getitem_column\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36m_getitem_column\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   2693\u001b[0m         \u001b[1;31m# get column\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2694\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mis_unique\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2695\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_item_cache\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2696\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2697\u001b[0m         \u001b[1;31m# duplicate columns & possible reduce dimensionality\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\core\\generic.py\u001b[0m in \u001b[0;36m_get_item_cache\u001b[1;34m(self, item)\u001b[0m\n\u001b[0;32m   2487\u001b[0m         \u001b[0mres\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcache\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2488\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mres\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2489\u001b[1;33m             \u001b[0mvalues\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_data\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2490\u001b[0m             \u001b[0mres\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_box_item_values\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalues\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2491\u001b[0m             \u001b[0mcache\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mitem\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mres\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\core\\internals.py\u001b[0m in \u001b[0;36mget\u001b[1;34m(self, item, fastpath)\u001b[0m\n\u001b[0;32m   4113\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4114\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0misna\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 4115\u001b[1;33m                 \u001b[0mloc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   4116\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4117\u001b[0m                 \u001b[0mindexer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0misna\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\core\\indexes\\base.py\u001b[0m in \u001b[0;36mget_loc\u001b[1;34m(self, key, method, tolerance)\u001b[0m\n\u001b[0;32m   3078\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3079\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3080\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_maybe_cast_indexer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3081\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3082\u001b[0m         \u001b[0mindexer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_indexer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmethod\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtolerance\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtolerance\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'user_id.y'"
     ]
    }
   ],
   "source": [
    "dataframe['highSchoolGPA'] = np.where(pd.isnull(dataframe[\"highSchoolGPA\"]), 0, dataframe[\"highSchoolGPA\"])\n",
    "dataframe['PubMathScore'] = np.where(pd.isnull(dataframe[\"PubMathScore\"]), 0, dataframe[\"PubMathScore\"])\n",
    "dataframe['parentsDependentsNum'] = np.where(pd.isnull(dataframe[\"parentsDependentsNum\"]), 0, dataframe[\"parentsDependentsNum\"])\n",
    "dataframe['parentsGraduateEdu'] = np.where(pd.isnull(dataframe[\"parentsGraduateEdu\"]), 0, dataframe[\"parentsGraduateEdu\"])\n",
    "dataframe['parentsHighIncome'] = np.where(pd.isnull(dataframe[\"parentsHighIncome\"]), 0, dataframe[\"parentsHighIncome\"])\n",
    "dataframe['birthYear'] = np.where(pd.isnull(dataframe[\"birthYear\"]), 0, dataframe[\"birthYear\"])\n",
    "dataframe['termCreditsGPA'] = np.where(pd.isnull(dataframe[\"termCreditsGPA\"]), 0, dataframe[\"termCreditsGPA\"])\n",
    "dataframe['termCreditsNoGPA'] = np.where(pd.isnull(dataframe[\"termCreditsNoGPA\"]), 0, dataframe[\"termCreditsNoGPA\"])\n",
    "dataframe['classStudentsNum'] = np.where(pd.isnull(dataframe[\"classStudentsNum\"]), 0, dataframe[\"classStudentsNum\"])\n",
    "dataframe['classGPA'] = np.where(pd.isnull(dataframe[\"classGPA\"]), 0, dataframe[\"classGPA\"])\n",
    "dataframe['exclClassCumGPA'] = np.where(pd.isnull(dataframe[\"exclClassCumGPA\"]), 0, dataframe[\"exclClassCumGPA\"])\n",
    "dataframe['singleParent'] = np.where(pd.isnull(dataframe[\"singleParent\"]), 0, dataframe[\"singleParent\"])\n",
    "dataframe['semesterWinter'] = np.where(pd.isnull(dataframe[\"semesterWinter\"]), 0, dataframe[\"semesterWinter\"])\n",
    "dataframe['instructor_1'] = np.where(pd.isnull(dataframe[\"instructor_1\"]), 0, dataframe[\"instructor_1\"])\n",
    "dataframe['Pass_Fail'] = np.where(pd.isnull(dataframe[\"Pass_Fail\"]), 0, dataframe[\"Pass_Fail\"])\n",
    "dataframe['Female'] = np.where(pd.isnull(dataframe[\"Female\"]), 0, dataframe[\"Female\"])\n",
    "dataframe['NonNativeEnglish'] = np.where(pd.isnull(dataframe[\"NonNativeEnglish\"]), 0, dataframe[\"NonNativeEnglish\"])\n",
    "dataframe['Asian'] = np.where(pd.isnull(dataframe[\"Asian\"]), 0, dataframe[\"Asian\"])\n",
    "dataframe['Hispanic'] = np.where(pd.isnull(dataframe[\"Hispanic\"]), 0, dataframe[\"Hispanic\"])\n",
    "dataframe['AfricanAmerican'] = np.where(pd.isnull(dataframe[\"AfricanAmerican\"]), 0, dataframe[\"AfricanAmerican\"])\n",
    "dataframe['OtherEthnicities'] = np.where(pd.isnull(dataframe[\"OtherEthnicities\"]), 0, dataframe[\"OtherEthnicities\"])\n",
    "dataframe['highSchoolMI'] = np.where(pd.isnull(dataframe[\"highSchoolMI\"]), 0, dataframe[\"highSchoolMI\"])\n",
    "dataframe['minorityGroup'] = np.where(pd.isnull(dataframe[\"minorityGroup\"]), 0, dataframe[\"minorityGroup\"])\n",
    "dataframe['international_1'] = np.where(pd.isnull(dataframe[\"international_1\"]), 0, dataframe[\"international_1\"])\n",
    "dataframe['Sophomore'] = np.where(pd.isnull(dataframe[\"Sophomore\"]), 0, dataframe[\"Sophomore\"])\n",
    "dataframe['Junior'] = np.where(pd.isnull(dataframe[\"Junior\"]), 0, dataframe[\"Junior\"])\n",
    "dataframe['Senior'] = np.where(pd.isnull(dataframe[\"Senior\"]), 0, dataframe[\"Senior\"])\n",
    "dataframe['Minors_1'] = np.where(pd.isnull(dataframe[\"Minors_1\"]), 0, dataframe[\"Minors_1\"])\n",
    "dataframe['Minors_2OrMore'] = np.where(pd.isnull(dataframe[\"Minors_2OrMore\"]), 0, dataframe[\"Minors_2OrMore\"])\n",
    "dataframe['athlete_1'] = np.where(pd.isnull(dataframe[\"athlete_1\"]), 0, dataframe[\"athlete_1\"])\n",
    "dataframe['honorsPro_1'] = np.where(pd.isnull(dataframe[\"honorsPro_1\"]), 0, dataframe[\"honorsPro_1\"])\n",
    "dataframe['programBusiness'] = np.where(pd.isnull(dataframe[\"programBusiness\"]), 0, dataframe[\"programBusiness\"])\n",
    "dataframe['programEngineering'] = np.where(pd.isnull(dataframe[\"programEngineering\"]), 0, dataframe[\"programEngineering\"])\n",
    "dataframe['programInformation'] = np.where(pd.isnull(dataframe[\"programInformation\"]), 0, dataframe[\"programInformation\"])\n",
    "dataframe['programOther'] = np.where(pd.isnull(dataframe[\"programOther\"]), 0, dataframe[\"programOther\"])\n",
    "# dataframe['trials_num'] = np.where(pd.isnull(dataframe[\"trials_num\"]), 0, dataframe[\"trials_num\"])\n",
    "# dataframe['e_factor'] = np.where(pd.isnull(dataframe[\"e_factor\"]), 0, dataframe[\"e_factor\"])\n",
    "# dataframe['i_interval'] = np.where(pd.isnull(dataframe[\"i_interval\"]), 0, dataframe[\"i_interval\"])\n",
    "# # of days since the beginning of the semester\n",
    "dataframe['days_offset'] = np.where(pd.isnull(dataframe[\"days_offset\"]), 0, dataframe[\"days_offset\"])\n",
    "dataframe['available_flashcards'] = np.where(pd.isnull(dataframe[\"available_flashcards\"]), 0, dataframe[\"available_flashcards\"])\n",
    "dataframe['majorsCount'] = np.where(pd.isnull(dataframe[\"majorsCount\"]), 1, dataframe[\"majorsCount\"])\n",
    "\n",
    "dataframe['firstTerm'] = np.where(pd.isnull(dataframe[\"firstTerm\"]), \"\", dataframe[\"firstTerm\"])\n",
    "dataframe['academicLoad'] = np.where(pd.isnull(dataframe[\"academicLoad\"]), \"\", dataframe[\"academicLoad\"])\n",
    "dataframe['careerLevel'] = np.where(pd.isnull(dataframe[\"careerLevel\"]), \"\", dataframe[\"careerLevel\"])\n",
    "dataframe['birthMonth'] = np.where(pd.isnull(dataframe[\"birthMonth\"]), \"\", dataframe[\"birthMonth\"])\n",
    "dataframe['residency'] = np.where(pd.isnull(dataframe[\"residency\"]), \"\", dataframe[\"residency\"])\n",
    "dataframe['residentialCollege'] = np.where(pd.isnull(dataframe[\"residentialCollege\"]), \"No\", dataframe[\"residentialCollege\"])\n",
    "# dataframe['section'] = np.where(pd.isnull(dataframe[\"section\"]), \"\", dataframe[\"section\"])\n",
    "dataframe['chapter_label'] = np.where(pd.isnull(dataframe[\"chapter_label\"]), \"\", dataframe[\"chapter_label\"])\n",
    "dataframe['sub_chapter_label'] = np.where(pd.isnull(dataframe[\"sub_chapter_label\"]), \"\", dataframe[\"sub_chapter_label\"])\n",
    "dataframe['question_name'] = np.where(pd.isnull(dataframe[\"question_name\"]), \"\", dataframe[\"question_name\"])\n",
    "\n",
    "dataframe['term'] = dataframe['term'].astype('category')\n",
    "dataframe['firstTerm'] = dataframe['firstTerm'].astype('category')\n",
    "dataframe['birthMonth'] = dataframe['birthMonth'].astype('category')\n",
    "dataframe['academicLoad'] = dataframe['academicLoad'].astype('category')\n",
    "dataframe['residency'] = dataframe['residency'].astype('category')\n",
    "# dataframe['section'] = dataframe['section'].astype('category')\n",
    "dataframe['user_id'] = dataframe['user_id.y'].astype(float)\n",
    "dataframe = dataframe.drop([\"user_id.y\"], axis=1)\n",
    "dataframe['user_id'] = dataframe['user_id'].astype(int)\n",
    "dataframe['user_id'] = dataframe['user_id'].astype(str)\n",
    "dataframe['user_id'] = dataframe['term'].str.cat(dataframe['user_id'], sep=':')\n",
    "dataframe['user_id'] = dataframe['user_id'].astype('category')\n",
    "dataframe['chapter_label'] = dataframe['chapter_label'].astype('category')\n",
    "dataframe['sub_chapter_label'] = dataframe['sub_chapter_label'].astype('category')\n",
    "dataframe['question_name'] = dataframe['question_name'].astype('category')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, '0', '1 Minor', '>= 2 Minors']"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(dataframe['minorsCount'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Sort',\n",
       " 'SimplePythonData',\n",
       " 'Selection',\n",
       " 'AdvancedAccumulation',\n",
       " 'Iteration',\n",
       " 'NestedData',\n",
       " 'Functions',\n",
       " 'PythonTurtle',\n",
       " 'Sequences',\n",
       " 'GeneralIntro',\n",
       " 'Tuples',\n",
       " 'DictionaryAccumulation',\n",
       " 'OptionalAndKeywordParameters',\n",
       " 'Exceptions',\n",
       " 'Dictionaries',\n",
       " 'RESTAPIs',\n",
       " 'Testing',\n",
       " 'PythonModules',\n",
       " 'StringFormatting',\n",
       " 'IndefiniteIteration',\n",
       " 'Conditionals',\n",
       " 'AdvancedFunctions',\n",
       " 'Sorting',\n",
       " 'Files',\n",
       " 'TransformingSequences',\n",
       " 'MoreAboutIteration',\n",
       " 'InternetAPIs',\n",
       " 'Classes',\n",
       " 'Inheritance',\n",
       " 'TestCases',\n",
       " 'APIsWithOAuth',\n",
       " 'Debugging']"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataframe = dataframe[~dataframe.chapter_label.isin(['Final_Exam_W15', 'Final_Exam_F15', 'Final_Exam_F16',\n",
    "                                                    'UMSI_106_F18', 'No', 'Final_Exam_F17'])]\n",
    "list(dataframe['chapter_label'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "224558 train examples\n",
      "56140 validation examples\n",
      "70175 test examples\n"
     ]
    }
   ],
   "source": [
    "train, test = train_test_split(dataframe, test_size=0.2)\n",
    "train, val = train_test_split(train, test_size=0.2)\n",
    "print(len(train), 'train examples')\n",
    "print(len(val), 'validation examples')\n",
    "print(len(test), 'test examples')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A utility method to create a tf.data dataset from a Pandas Dataframe\n",
    "def df_to_dataset(dataframe, shuffle=True, batch_size=32):\n",
    "  dataframe = dataframe.copy()\n",
    "  labels = dataframe.pop('target')\n",
    "  ds = tf.data.Dataset.from_tensor_slices((dict(dataframe), labels))\n",
    "  if shuffle:\n",
    "    ds = ds.shuffle(buffer_size=len(dataframe))\n",
    "  ds = ds.batch(batch_size)\n",
    "  return ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Every feature: ['term', 'firstTerm', 'highSchoolGPA', 'PubMathScore', 'parentsDependentsNum', 'singleParent', 'birthMonth', 'birthYear', 'majorsCount', 'academicLoad', 'careerLevel', 'residency', 'residentialCollege', 'termCreditsGPA', 'termCreditsNoGPA', 'classStudentsNum', 'classGPA', 'exclClassCumGPA', 'section', 'semesterWinter', 'instructor_1', 'Pass_Fail', 'Female', 'NonNativeEnglish', 'White', 'Asian', 'WhiteOrAsian', 'Hispanic', 'AfricanAmerican', 'OtherEthnicities', 'parentsGraduateEdu', 'parentsHighIncome', 'highSchoolMI', 'minorityGroup', 'international_1', 'Junior', 'Sophomore', 'Senior', 'Minors_1', 'Minors_2OrMore', 'athlete_1', 'honorsPro_1', 'programBusiness', 'programEngineering', 'programInformation', 'programOther', 'chapter_label', 'sub_chapter_label', 'question_name', 'i_interval', 'e_factor', 'trials_num', 'days_offset', 'available_flashcards', 'user_id']\n",
      "A batch of terms: tf.Tensor(\n",
      "[b'WN 2019' b'FA 2019' b'FA 2019' b'FA 2019' b'FA 2019' b'WN 2018'\n",
      " b'FA 2019' b'FA 2018' b'FA 2019' b'WN 2019' b'FA 2019' b'WN 2018'\n",
      " b'FA 2019' b'FA 2019' b'FA 2018' b'WN 2019' b'FA 2018' b'WN 2018'\n",
      " b'FA 2019' b'FA 2019' b'FA 2019' b'WN 2018' b'WN 2019' b'FA 2018'\n",
      " b'FA 2019' b'FA 2019' b'WN 2019' b'WN 2019' b'WN 2018' b'FA 2019'\n",
      " b'FA 2019' b'WN 2018'], shape=(32,), dtype=string)\n",
      "A batch of targets: tf.Tensor([0 1 1 1 0 1 0 1 1 1 1 0 0 1 1 1 1 1 1 0 1 0 0 1 1 0 0 1 0 0 1 1], shape=(32,), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "for feature_batch, label_batch in train_ds.take(1):\n",
    "  print('Every feature:', list(feature_batch.keys()))\n",
    "  print('A batch of terms:', feature_batch['term'])\n",
    "  print('A batch of targets:', label_batch )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array(['SI 106 001 - UC 109 001'], dtype=object),\n",
       " array([350873], dtype=int64))"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unique, counts = np.unique(dataframe[\"section\"], return_counts=True)\n",
    "unique, counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "term                    category\n",
       "firstTerm               category\n",
       "highSchoolGPA            float64\n",
       "PubMathScore             float64\n",
       "parentsDependentsNum     float64\n",
       "singleParent               int64\n",
       "birthMonth              category\n",
       "birthYear                  int64\n",
       "majorsCount                int64\n",
       "academicLoad            category\n",
       "careerLevel               object\n",
       "residency               category\n",
       "residentialCollege        object\n",
       "termCreditsGPA           float64\n",
       "termCreditsNoGPA         float64\n",
       "classStudentsNum           int64\n",
       "classGPA                 float64\n",
       "exclClassCumGPA          float64\n",
       "section                 category\n",
       "semesterWinter             int64\n",
       "instructor_1               int64\n",
       "Pass_Fail                  int64\n",
       "Female                     int64\n",
       "NonNativeEnglish           int64\n",
       "White                      int64\n",
       "Asian                      int64\n",
       "WhiteOrAsian               int64\n",
       "Hispanic                   int64\n",
       "AfricanAmerican            int64\n",
       "OtherEthnicities           int64\n",
       "parentsGraduateEdu         int64\n",
       "parentsHighIncome        float64\n",
       "highSchoolMI             float64\n",
       "minorityGroup              int64\n",
       "international_1            int64\n",
       "Junior                     int64\n",
       "Sophomore                  int64\n",
       "Senior                     int64\n",
       "Minors_1                   int64\n",
       "Minors_2OrMore             int64\n",
       "athlete_1                  int64\n",
       "honorsPro_1                int64\n",
       "programBusiness            int64\n",
       "programEngineering         int64\n",
       "programInformation         int64\n",
       "programOther               int64\n",
       "chapter_label           category\n",
       "sub_chapter_label       category\n",
       "question_name           category\n",
       "i_interval                 int64\n",
       "e_factor                 float64\n",
       "trials_num                 int64\n",
       "days_offset                int64\n",
       "target                     int32\n",
       "available_flashcards       int64\n",
       "user_id                 category\n",
       "dtype: object"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataframe.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_columns = []\n",
    "\n",
    "# numeric cols\n",
    "for header in ['highSchoolGPA',\n",
    "    'PubMathScore',\n",
    "    'parentsDependentsNum',\n",
    "    'parentsGraduateEdu',\n",
    "    'parentsHighIncome',\n",
    "    'birthYear',\n",
    "    'termCreditsGPA',\n",
    "    'termCreditsNoGPA',\n",
    "    'classStudentsNum',\n",
    "    'classGPA',\n",
    "    'exclClassCumGPA',\n",
    "    'singleParent',\n",
    "    'semesterWinter',\n",
    "    'instructor_1',\n",
    "    'Pass_Fail',\n",
    "    'Female',\n",
    "    'NonNativeEnglish',\n",
    "    'Asian',\n",
    "    'Hispanic',\n",
    "    'AfricanAmerican',\n",
    "    'OtherEthnicities',\n",
    "    'highSchoolMI',\n",
    "    'minorityGroup',\n",
    "    'international_1',\n",
    "    'Sophomore',\n",
    "    'Junior',\n",
    "    'Senior',\n",
    "    'Minors_1',\n",
    "    'Minors_2OrMore',\n",
    "    'athlete_1',\n",
    "    'honorsPro_1',\n",
    "    'programBusiness',\n",
    "    'programEngineering',\n",
    "    'programInformation',\n",
    "    'programOther',\n",
    "    'days_offset',\n",
    "    'available_flashcards']:\n",
    "  feature_columns.append(feature_column.numeric_column(header))\n",
    "\n",
    "# bucketized cols\n",
    "# age_buckets = feature_column.bucketized_column(age, boundaries=[18, 25, 30, 35, 40, 45, 50, 55, 60, 65])\n",
    "# feature_columns.append(age_buckets)\n",
    "\n",
    "# indicator cols\n",
    "user_id = feature_column.categorical_column_with_vocabulary_list(\n",
    "      'user_id', np.unique(dataframe[\"user_id\"]).tolist())\n",
    "user_id_one_hot = feature_column.indicator_column(user_id)\n",
    "feature_columns.append(user_id_one_hot)\n",
    "\n",
    "term = feature_column.categorical_column_with_vocabulary_list(\n",
    "      'term', np.unique(dataframe[\"term\"]).tolist())\n",
    "term_one_hot = feature_column.indicator_column(term)\n",
    "feature_columns.append(term_one_hot)\n",
    "\n",
    "firstTerm = feature_column.categorical_column_with_vocabulary_list(\n",
    "      'firstTerm', np.unique(dataframe[\"firstTerm\"]).tolist())\n",
    "firstTerm_one_hot = feature_column.indicator_column(firstTerm)\n",
    "feature_columns.append(firstTerm_one_hot)\n",
    "\n",
    "majorsCount = feature_column.categorical_column_with_vocabulary_list(\n",
    "      'majorsCount', np.unique(dataframe[\"majorsCount\"]).tolist())\n",
    "majorsCount_one_hot = feature_column.indicator_column(majorsCount)\n",
    "feature_columns.append(majorsCount_one_hot)\n",
    "\n",
    "academicLoad = feature_column.categorical_column_with_vocabulary_list(\n",
    "      'academicLoad', np.unique(dataframe[\"academicLoad\"]).tolist())\n",
    "academicLoad_one_hot = feature_column.indicator_column(academicLoad)\n",
    "feature_columns.append(academicLoad_one_hot)\n",
    "\n",
    "careerLevel = feature_column.categorical_column_with_vocabulary_list(\n",
    "      'careerLevel', np.unique(dataframe[\"careerLevel\"]).tolist())\n",
    "careerLevel_one_hot = feature_column.indicator_column(careerLevel)\n",
    "feature_columns.append(careerLevel_one_hot)\n",
    "\n",
    "birthMonth = feature_column.categorical_column_with_vocabulary_list(\n",
    "      'birthMonth', np.unique(dataframe[\"birthMonth\"]).tolist())\n",
    "birthMonth_one_hot = feature_column.indicator_column(birthMonth)\n",
    "feature_columns.append(birthMonth_one_hot)\n",
    "\n",
    "residency = feature_column.categorical_column_with_vocabulary_list(\n",
    "      'residency', np.unique(dataframe[\"residency\"]).tolist())\n",
    "residency_one_hot = feature_column.indicator_column(residency)\n",
    "feature_columns.append(residency_one_hot)\n",
    "\n",
    "residentialCollege = feature_column.categorical_column_with_vocabulary_list(\n",
    "      'residentialCollege', np.unique(dataframe[\"residentialCollege\"]).tolist())\n",
    "residentialCollege_one_hot = feature_column.indicator_column(residentialCollege)\n",
    "feature_columns.append(residentialCollege_one_hot)\n",
    "\n",
    "chapter_label = feature_column.categorical_column_with_vocabulary_list(\n",
    "      'chapter_label', np.unique(dataframe[\"chapter_label\"]).tolist())\n",
    "chapter_label_one_hot = feature_column.indicator_column(chapter_label)\n",
    "feature_columns.append(chapter_label_one_hot)\n",
    "\n",
    "sub_chapter_label = feature_column.categorical_column_with_vocabulary_list(\n",
    "      'sub_chapter_label', np.unique(dataframe[\"sub_chapter_label\"]).tolist())\n",
    "sub_chapter_label_one_hot = feature_column.indicator_column(sub_chapter_label)\n",
    "feature_columns.append(sub_chapter_label_one_hot)\n",
    "\n",
    "question_name = feature_column.categorical_column_with_vocabulary_list(\n",
    "      'question_name', np.unique(dataframe[\"question_name\"]).tolist())\n",
    "question_name_one_hot = feature_column.indicator_column(question_name)\n",
    "feature_columns.append(question_name_one_hot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_layer = tf.keras.layers.DenseFeatures(feature_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 500\n",
    "train_ds = df_to_dataset(train)\n",
    "val_ds = df_to_dataset(val, shuffle=False)\n",
    "test_ds = df_to_dataset(test, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer sequential_5 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "Epoch 1/40\n",
      "7018/7018 [==============================] - 512s 73ms/step - loss: 0.6470 - accuracy: 0.6642\n",
      "Epoch 2/40\n",
      "7018/7018 [==============================] - 530s 76ms/step - loss: 0.5246 - accuracy: 0.7360\n",
      "Epoch 3/40\n",
      "3558/7018 [==============>...............] - ETA: 4:03 - loss: 0.5048 - accuracy: 0.7517"
     ]
    }
   ],
   "source": [
    "model = tf.keras.Sequential([\n",
    "  feature_layer,\n",
    "  layers.Dense(400, activation='relu'),\n",
    "  layers.Dense(250, activation='relu'),\n",
    "  layers.Dense(100, activation='relu'),\n",
    "  layers.Dense(40, activation='relu'),\n",
    "  layers.Dense(1, activation='sigmoid')\n",
    "])\n",
    "\n",
    "model.compile(optimizer='adam',\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.fit(train_ds,\n",
    "#           validation_data=val_ds,\n",
    "          epochs=40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1515/1515 [==============================] - 73s 48ms/step - loss: 0.4600 - accuracy: 0.7828\n",
      "Accuracy 0.7828168\n"
     ]
    }
   ],
   "source": [
    "loss, accuracy = model.evaluate(test_ds)\n",
    "print(\"Accuracy\", accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
